{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04584e12-1171-4f96-a1e3-b01a25df59f7",
   "metadata": {},
   "source": [
    "### About Project\n",
    "This project devided into **three notebooks** that explained the usage of TF-IDF using **English.** The process flow of this project start from data collection (corpus) to pre-processing and algorithm fitting, the detailed steps explained below:\n",
    "1. **Data Collection (self-produce)**\n",
    "2. **Text Pre-Processing (Case Folding, Punctuation Removal, Tokenizing,Stop-Words Removal, Stemming)**\n",
    "3. **TF-IDF Algorithm & VSM Implementation**\n",
    "4. **Boolean Retrieval Algorithm Implementation**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "749d1fc5-5bc8-4f96-b375-6018b7f782f4",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### The Notebook Divided into three sub-process:\n",
    "1. text-preprocessing-english.ipynb\n",
    "2. implementation-tf-idf-and-vsm.ipynb\n",
    "3. implementation-boolean.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2172384d-45f9-4a61-8e71-ce12d8654cde",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Boolean Information Retrieval\n",
    "Boolean Information Retrieval is a foundational model in information retrieval that uses Boolean logic to match documents against a userâ€™s query. It relies on the principles of Boolean algebra, using logical operators to define the relationships between terms.\n",
    "\n",
    "- **Boolean Operators**: The primary Boolean operators are AND, OR, and NOT. These operators are used to combine or exclude terms in a query:\n",
    "\n",
    "> **AND: All terms must be present in the document.**\n",
    "> \n",
    "> For example, the query \"cats AND dogs\" will retrieve documents containing both \"cats\" and \"dogs\".\n",
    "\n",
    "\n",
    "> **OR: At least one of the terms must be present in the document.**\n",
    "> \n",
    "> For example, the query \"cats OR dogs\" will retrieve documents containing either \"cats\" or \"dogs\" or both.\n",
    "\n",
    "\n",
    "> **NOT: Excludes documents containing the term.**\n",
    "> \n",
    "> For example, the query \"cats NOT dogs\" will retrieve documents containing \"cats\" but not \"dogs\".\n",
    "\n",
    "- **Query Formulation**: Users formulate queries using Boolean operators to express their information needs precisely. This method allows for complex and highly specific queries.\n",
    "\n",
    "- **Document Representation**: Documents are typically represented as sets of terms. The presence or absence of terms in a document is used to determine if the document matches the query.\n",
    "\n",
    "Boolean Information Retrieval provides a straightforward and powerful way to perform text searches, especially in structured databases and for well-defined queries. Despite its simplicity, it forms the basis for more advanced retrieval models and remains an important tool in the field of information retrieval."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c3830f0-164d-4839-9682-9f05ca6db838",
   "metadata": {
    "id": "9MsVvRo3LQtO"
   },
   "source": [
    "## Library Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e3dac22-4544-4d7e-957e-8a9742ba6ea6",
   "metadata": {
    "id": "vaTjE7WVJ9Yg",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import regex as re\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81719ff2-00c1-4dfd-bf7c-cc60e2346dd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/bagussatya/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/bagussatya/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89555b4b-427a-4b8a-9d5e-8228137ab667",
   "metadata": {
    "id": "7WRDPr7sLGSO",
    "tags": []
   },
   "source": [
    "## Importing Dataset for English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9615d29a-7379-41b0-b783-fa8bc0c70b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "  clean_text = []\n",
    "  stemmer = PorterStemmer()\n",
    "\n",
    "  for t in text:\n",
    "      clean = re.sub(r'[^\\w\\s]', '', t.lower())\n",
    "      clean = re.sub(r'\\d+', '', clean)\n",
    "      tokens = word_tokenize(clean)\n",
    "      stemmed_tokens = [stemmer.stem(token) for token in tokens]\n",
    "      clean_text.append(' '.join(stemmed_tokens))\n",
    "\n",
    "  return clean_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac7638c-618c-41e8-a5d9-2b6d1c99f91b",
   "metadata": {
    "id": "7WRDPr7sLGSO",
    "tags": []
   },
   "source": [
    "### Importing Cleaned Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac60a6a3-32ce-4c3b-a8cb-ba58e09fe967",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 745
    },
    "id": "asgylMmTJ9md",
    "outputId": "5f1f6ff6-a460-4392-fc53-2e28417569ea",
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>teks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>call bird habit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>brother like bird month father gave black bird</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>antoni bird lost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>greedi characterist hate</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             teks\n",
       "0                                 call bird habit\n",
       "1  brother like bird month father gave black bird\n",
       "2                                antoni bird lost\n",
       "3                        greedi characterist hate"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.expand_frame_repr', False)\n",
    "pd.set_option('display.max_colwidth', 1000)\n",
    "\n",
    "dataset = pd.read_csv(\"clean-corpus-inggris.csv\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63aa4164-52e8-49c2-bc63-24587461cd1b",
   "metadata": {},
   "source": [
    "### Importing Un-Preprocessed Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "129e4399-2cf8-48fc-9459-ed009ab3f4f1",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ENG1</td>\n",
       "      <td>They called him a bird, because of his habit</td>\n",
       "      <td>bird</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENG2</td>\n",
       "      <td>My brother likes bird and after a month my father gave him a black bird</td>\n",
       "      <td>bird</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ENG3</td>\n",
       "      <td>Antony has a bird and he lost it</td>\n",
       "      <td>bird</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ENG4</td>\n",
       "      <td>Greedy is the most characteristic that I hate</td>\n",
       "      <td>hate</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id                                                                     text topic\n",
       "0  ENG1                             They called him a bird, because of his habit  bird\n",
       "1  ENG2  My brother likes bird and after a month my father gave him a black bird  bird\n",
       "2  ENG3                                         Antony has a bird and he lost it  bird\n",
       "3  ENG4                            Greedy is the most characteristic that I hate  hate"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate = pd.read_csv(\"corpus-inggris.csv\").head(4)\n",
    "validate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c24bfa-9165-4ce0-aa5e-441e699214ac",
   "metadata": {},
   "source": [
    "### Corpus Preparations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a8db0bb2-7970-414a-b5c9-b50434e8e1ac",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['call bird habit',\n",
       " 'brother like bird month father gave black bird',\n",
       " 'antoni bird lost',\n",
       " 'greedi characterist hate']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = dataset.teks.tolist()\n",
    "corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d48be41d-1438-47da-b586-f356f7188547",
   "metadata": {},
   "source": [
    "#### Looking to display the unique words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de3b1e9b-da9e-4fc2-b985-2e2c191bc0cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'antoni',\n",
       " 'bird',\n",
       " 'black',\n",
       " 'brother',\n",
       " 'call',\n",
       " 'characterist',\n",
       " 'father',\n",
       " 'gave',\n",
       " 'greedi',\n",
       " 'habit',\n",
       " 'hate',\n",
       " 'like',\n",
       " 'lost',\n",
       " 'month'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_words = set()\n",
    "for sentence in corpus:\n",
    "    words = sentence.split()\n",
    "    unique_words.update(words)\n",
    "unique_words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf1d2300-1cb0-4c16-a622-f042d8813ffc",
   "metadata": {},
   "source": [
    "### TF (Term Frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "a05b445d-489b-405d-8c99-22a3378153b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf(text):\n",
    "    word_count_per_document = {}\n",
    "\n",
    "    for i, sentence in enumerate(text, start=0):\n",
    "        words = sentence.split()\n",
    "        for word in words:\n",
    "            if word in word_count_per_document:\n",
    "                if i in word_count_per_document[word]:\n",
    "                    word_count_per_document[word][i] += 1\n",
    "                else:\n",
    "                    word_count_per_document[word][i] = 1\n",
    "            else:\n",
    "                word_count_per_document[word] = {i: 1}\n",
    "\n",
    "    df_term_frequency = pd.DataFrame(word_count_per_document)\n",
    "    df_term_frequency.fillna(0, inplace=True)\n",
    "    return df_term_frequency.T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4384b2b9-01a1-4d64-8702-be9aff71aa6a",
   "metadata": {},
   "source": [
    "#### Searching for the document term frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "05142a00-0ad8-4e07-af05-380a524bdc07",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>call</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bird</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>habit</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brother</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>like</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>month</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>father</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gave</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>black</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>antoni</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lost</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>greedi</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>characterist</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hate</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0    1    2    3\n",
       "call          1.0  0.0  0.0  0.0\n",
       "bird          1.0  2.0  1.0  0.0\n",
       "habit         1.0  0.0  0.0  0.0\n",
       "brother       0.0  1.0  0.0  0.0\n",
       "like          0.0  1.0  0.0  0.0\n",
       "month         0.0  1.0  0.0  0.0\n",
       "father        0.0  1.0  0.0  0.0\n",
       "gave          0.0  1.0  0.0  0.0\n",
       "black         0.0  1.0  0.0  0.0\n",
       "antoni        0.0  0.0  1.0  0.0\n",
       "lost          0.0  0.0  1.0  0.0\n",
       "greedi        0.0  0.0  0.0  1.0\n",
       "characterist  0.0  0.0  0.0  1.0\n",
       "hate          0.0  0.0  0.0  1.0"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_document= tf(corpus).T.sort_index().T\n",
    "tf_document"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a312c6a-ee2c-40ed-89e9-e091910f5dd2",
   "metadata": {},
   "source": [
    "#### Transforming the Frequency into only 1 and 0\n",
    "p.s. This process done to eliminate the frequency so that it only shows \"available\" or \"not available\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "5b01de78-7cd9-435d-8e90-9204b320c7a4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>call</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bird</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>habit</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brother</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>like</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>month</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>father</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gave</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>black</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>antoni</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lost</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>greedi</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>characterist</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hate</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0    1    2    3\n",
       "call          1.0  0.0  0.0  0.0\n",
       "bird          1.0  1.0  1.0  0.0\n",
       "habit         1.0  0.0  0.0  0.0\n",
       "brother       0.0  1.0  0.0  0.0\n",
       "like          0.0  1.0  0.0  0.0\n",
       "month         0.0  1.0  0.0  0.0\n",
       "father        0.0  1.0  0.0  0.0\n",
       "gave          0.0  1.0  0.0  0.0\n",
       "black         0.0  1.0  0.0  0.0\n",
       "antoni        0.0  0.0  1.0  0.0\n",
       "lost          0.0  0.0  1.0  0.0\n",
       "greedi        0.0  0.0  0.0  1.0\n",
       "characterist  0.0  0.0  0.0  1.0\n",
       "hate          0.0  0.0  0.0  1.0"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_document[tf_document != 0] = 1\n",
    "tf_document"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fbc6318-e4be-4949-b44e-2ca9c7e3fff1",
   "metadata": {},
   "source": [
    "### Availablity Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "6a4702e3-1058-434c-bac4-c432456b83d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_mapping = []\n",
    "documents = {}\n",
    "for i in range(len(unique_words)):\n",
    "    mapp = tf_document.iloc[i].values.astype(int).tolist()\n",
    "    documents[tf_document.index[i]] = mapp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc8cd78-2b71-4738-b638-5b24022c8edb",
   "metadata": {},
   "source": [
    "### Query imputation and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8ed99e05-c1b2-4d04-98d7-3d8b7ef15f7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Insert a query:  bird and list\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'bird and list'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = input(\"Insert a query: \")\n",
    "query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a70ab81-550b-42f8-ba83-2d69f7165cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def boolean_rules():\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cb8fd13e-80eb-49b7-8350-3cb132761e5d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Insert a query:\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " bird and elephant\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of words in the query:\n",
      " ['bird', 'and', 'elephant']\n",
      "List of the queries:\n",
      " ['bird', 'and', 'elephant']\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "08aa9c20-209f-4f83-98ea-0890d4600cb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_document.loc[\"call\"].values.astype(int) & tf_document.loc[\"lost\"].values.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "8f66052b-67ba-4477-9444-49b73e912e6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 1])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "~ np.array([1,1,0,1,0]) * np.array([0,0,0,1,1]) & np.array([0,0,1,1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "093b42de-dbc4-40b0-a2fb-ea2143990b8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b598e9c-2422-43ce-b966-bf6a759599d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = result.intersection(documents[next_token])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b3337d-b2e8-40ee-8a74-81683e4de4e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c56bca-f2ff-4c0d-af71-cc42e7a64fc9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d114b285-d6e5-4cbb-9e46-f5235242b825",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a05980-a952-4562-a9a2-b98c1ce157e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66bafecd-9514-4392-8ffb-b5cd81375015",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d3c49e-b2b1-4c25-a4d7-7a3b9b3f90ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "205a467b-eaad-45bf-9d42-828305f304e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "39af85c4-2693-4406-be79-ce309d10eefb",
   "metadata": {},
   "source": [
    "### Scikit-learn TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "65696a57-be5b-4c98-809f-a841ae1c0fe0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bag_of_words = []\n",
    "for index, var in enumerate(corpus_eng):\n",
    "    dict_of_words = var.split()\n",
    "    bag_of_words.append(dict_of_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ca6dfc4a-d08f-463f-aa19-eacf87bc1697",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['call', 'bird', 'habit'], ['brother', 'like', 'bird', 'month', 'father', 'gave', 'black', 'bird'], ['antoni', 'bird', 'lost'], ['greedi', 'characterist', 'hate'], ['bird', 'two', 'wing', 'two', 'leg'], ['sustain', 'becom', 'key', 'focu', 'consum', 'electron', 'nokia', 'set', 'apart', 'priorit', 'ecofriendli', 'practic', 'manufactur', 'process', 'align', 'grow', 'demand', 'ethic', 'sourc', 'recycl', 'mobil', 'devic'], ['advent', 'augment', 'realiti', 'applic', 'smartphon', 'like', 'iphon', 'transform', 'versatil', 'tool', 'blur', 'line', 'digit', 'physic', 'realm', 'offer', 'user', 'immers', 'experi', 'previous', 'unimagin'], ['smartphon', 'manufactur', 'strive', 'market', 'domin', 'iphon', 'distinguish', 'seamless', 'ecosystem', 'integr', 'hardwar', 'softwar', 'servic', 'creat', 'cohes', 'user', 'experi', 'unparallel', 'competitor'], ['era', 'privaci', 'concern', 'loom', 'larg', 'iphon', 'stand', 'robust', 'secur', 'featur', 'provid', 'user', 'peac', 'mind', 'amidst', 'grow', 'threat', 'person', 'data', 'smartphon'], ['nokia', 'synonym', 'mobil', 'innov', 'undergo', 'resurg', 'telecommun', 'industri', 'leverag', 'heritag', 'reintroduc', 'icon', 'design', 'infus', 'modern', 'technolog', 'advanc'], ['cellular', 'biolog', 'research', 'uncov', 'intric', 'mechan', 'govern', 'cell', 'signal', 'pathway', 'shed', 'light', 'fundament', 'process', 'crucial', 'understand', 'human', 'health', 'diseas'], ['neurobiolog', 'elucid', 'neural', 'circuitri', 'underli', 'learn', 'memori', 'requir', 'precis', 'manipul', 'neural', 'cell', 'prompt', 'develop', 'innov', 'techniqu', 'cell', 'manipul', 'record'], ['environment', 'scientist', 'examin', 'ecolog', 'footprint', 'beverag', 'product', 'assess', 'sustain', 'water', 'usag', 'packag', 'materi', 'mitig', 'environment', 'impact', 'manufactur', 'popular', 'drink', 'soda', 'bottl', 'water'], ['certain', 'profess', 'bartend', 'hospit', 'master', 'art', 'mixolog', 'essenti', 'requir', 'nuanc', 'understand', 'differ', 'ingredi', 'interact', 'creat', 'harmoni', 'flavor', 'drink', 'experi'], ['social', 'gather', 'individu', 'often', 'find', 'compel', 'drink', 'excess', 'unawar', 'potenti', 'consequ', 'impair', 'judgment', 'dehydr']]\n"
     ]
    }
   ],
   "source": [
    "print(bag_of_words, sep=', ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "264a7dfa-0bd9-48fc-b3b5-5b8b11134bbb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['call', 'bird', 'habit']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_of_words[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "25d1d5d1-17f7-49e4-9a85-1506c5ecfbba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "token_bank = {}\n",
    "for index, var in enumerate(bag_of_words):\n",
    "    for parameter, temp in enumerate(var):\n",
    "        if temp not in token_bank:\n",
    "            token_bank[temp] = 1\n",
    "        else:\n",
    "            token_bank[temp]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8e459db1-e0ba-4a80-a47a-193809bcd3b7",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'call': 1, 'bird': 5, 'habit': 1, 'brother': 1, 'like': 2, 'month': 1, 'father': 1, 'gave': 1, 'black': 1, 'antoni': 1, 'lost': 1, 'greedi': 1, 'characterist': 1, 'hate': 1, 'two': 2, 'wing': 1, 'leg': 1, 'sustain': 2, 'becom': 1, 'key': 1, 'focu': 1, 'consum': 1, 'electron': 1, 'nokia': 2, 'set': 1, 'apart': 1, 'priorit': 1, 'ecofriendli': 1, 'practic': 1, 'manufactur': 3, 'process': 2, 'align': 1, 'grow': 2, 'demand': 1, 'ethic': 1, 'sourc': 1, 'recycl': 1, 'mobil': 2, 'devic': 1, 'advent': 1, 'augment': 1, 'realiti': 1, 'applic': 1, 'smartphon': 3, 'iphon': 3, 'transform': 1, 'versatil': 1, 'tool': 1, 'blur': 1, 'line': 1, 'digit': 1, 'physic': 1, 'realm': 1, 'offer': 1, 'user': 3, 'immers': 1, 'experi': 3, 'previous': 1, 'unimagin': 1, 'strive': 1, 'market': 1, 'domin': 1, 'distinguish': 1, 'seamless': 1, 'ecosystem': 1, 'integr': 1, 'hardwar': 1, 'softwar': 1, 'servic': 1, 'creat': 2, 'cohes': 1, 'unparallel': 1, 'competitor': 1, 'era': 1, 'privaci': 1, 'concern': 1, 'loom': 1, 'larg': 1, 'stand': 1, 'robust': 1, 'secur': 1, 'featur': 1, 'provid': 1, 'peac': 1, 'mind': 1, 'amidst': 1, 'threat': 1, 'person': 1, 'data': 1, 'synonym': 1, 'innov': 2, 'undergo': 1, 'resurg': 1, 'telecommun': 1, 'industri': 1, 'leverag': 1, 'heritag': 1, 'reintroduc': 1, 'icon': 1, 'design': 1, 'infus': 1, 'modern': 1, 'technolog': 1, 'advanc': 1, 'cellular': 1, 'biolog': 1, 'research': 1, 'uncov': 1, 'intric': 1, 'mechan': 1, 'govern': 1, 'cell': 3, 'signal': 1, 'pathway': 1, 'shed': 1, 'light': 1, 'fundament': 1, 'crucial': 1, 'understand': 2, 'human': 1, 'health': 1, 'diseas': 1, 'neurobiolog': 1, 'elucid': 1, 'neural': 2, 'circuitri': 1, 'underli': 1, 'learn': 1, 'memori': 1, 'requir': 2, 'precis': 1, 'manipul': 2, 'prompt': 1, 'develop': 1, 'techniqu': 1, 'record': 1, 'environment': 2, 'scientist': 1, 'examin': 1, 'ecolog': 1, 'footprint': 1, 'beverag': 1, 'product': 1, 'assess': 1, 'water': 2, 'usag': 1, 'packag': 1, 'materi': 1, 'mitig': 1, 'impact': 1, 'popular': 1, 'drink': 3, 'soda': 1, 'bottl': 1, 'certain': 1, 'profess': 1, 'bartend': 1, 'hospit': 1, 'master': 1, 'art': 1, 'mixolog': 1, 'essenti': 1, 'nuanc': 1, 'differ': 1, 'ingredi': 1, 'interact': 1, 'harmoni': 1, 'flavor': 1, 'social': 1, 'gather': 1, 'individu': 1, 'often': 1, 'find': 1, 'compel': 1, 'excess': 1, 'unawar': 1, 'potenti': 1, 'consequ': 1, 'impair': 1, 'judgment': 1, 'dehydr': 1}\n"
     ]
    }
   ],
   "source": [
    "print(token_bank, sep=', ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "26efb12c-d7d6-4c6a-a997-981039766524",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count of unique words: 181\n"
     ]
    }
   ],
   "source": [
    "print(f\"count of unique words: {len(token_bank)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "14d209ad-daa4-4cd9-b8d5-0095fc531650",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b179d7f4-b8d0-4aba-b571-2a938c6fbc8d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['not', 'and', 'or', '(', ')']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bop = {\n",
    "    'not':3,\n",
    "    'and':2,\n",
    "    'or':1,\n",
    "    '(':0,\n",
    "    ')':0\n",
    "}\n",
    "\n",
    "BO = list(bop.keys())\n",
    "BO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "ae99e6d7-f4f8-44f0-9d2e-a6ae6bf3daf2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "masukan kata: Fundamental, Or Memory\n"
     ]
    }
   ],
   "source": [
    "masuk = \"\"\n",
    "masukan = input(f\"masukan kata:{masuk}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "59847e2d-2849-40a8-b073-2e0cfc8d0c7e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Fundamental,', 'Or', 'Memory']"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_masukan = masukan.split()\n",
    "list_of_masukan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "fbd51f21-a74f-47b6-8736-945d26856998",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "st = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "bf5dd585-f031-45c0-9054-17bcac992dc3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fundament', 'or', 'memori']\n"
     ]
    }
   ],
   "source": [
    "clean_input = []\n",
    "for index, teks in enumerate(list_of_masukan):\n",
    "    clean = re.sub(r'[^\\w\\s]','',teks.lower())\n",
    "    stemword = st.stem(clean)\n",
    "    clean_input.append(stemword)\n",
    "print(clean_input, sep=', ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "186e7bf0-422f-4682-8c25-f9dbf9e59d3c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "infix = clean_input\n",
    "postfix = []\n",
    "stack = []\n",
    "scanned_operator = \"\"\n",
    "\n",
    "if len(infix) > 0:\n",
    "    II = 0\n",
    "    while II < len(infix):\n",
    "        if infix[II] not in BO:\n",
    "            postfix.append(infix[II])\n",
    "            II+=1\n",
    "        else:\n",
    "            scanned_operator = infix[II]\n",
    "            if len(stack) == 0:\n",
    "                stack.append(scanned_operator)\n",
    "                II+=1\n",
    "            elif scanned_operator == \"(\":\n",
    "                stack.append(scanned_operator)\n",
    "                II+=1\n",
    "            elif scanned_operator ==\")\":\n",
    "                postfix.append(stack.pop())\n",
    "                while len(stack) != 0:\n",
    "                    if stack[-1] != \"(\":\n",
    "                        postfix.append(stack.pop())\n",
    "                    else:\n",
    "                        stack.pop()\n",
    "                II+=1\n",
    "            II+=1\n",
    "elif BOP[stack[-1]] >= BOP[scanned_operator]:\n",
    "    postfix.append(stack.pop())\n",
    "    stack.append(scanned_operator)\n",
    "    II+=1\n",
    "else:\n",
    "    stack.append(scanned_operator)\n",
    "    II+=1\n",
    "while len(stack)>0:\n",
    "    postfix.append(stack.pop())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "43001311-638e-4b49-949e-90794e307039",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fundament', 'or']"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "postfix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "b096618e-0b70-4e14-8c7d-fe60c20fe7d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mappedQuery = {}\n",
    "BO = ['and', 'or', 'not']\n",
    "for index, var in enumerate(bag_of_words):\n",
    "    templist = []\n",
    "    for item in postfix:\n",
    "        if item in BO:\n",
    "            templist.append(item)\n",
    "        else:\n",
    "            if item in var:\n",
    "                templist.append(True)\n",
    "            else:\n",
    "                templist.append(False)\n",
    "    mappedQuery[index] = templist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "d6527e5b-bdf8-42f5-8ef2-61428d961d18",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: [False, 'or'], 1: [False, 'or'], 2: [False, 'or'], 3: [False, 'or'], 4: [False, 'or'], 5: [False, 'or'], 6: [False, 'or'], 7: [False, 'or'], 8: [False, 'or'], 9: [False, 'or'], 10: [True, 'or'], 11: [False, 'or'], 12: [False, 'or'], 13: [False, 'or'], 14: [False, 'or']}\n"
     ]
    }
   ],
   "source": [
    "print(mappedQuery, sep=', ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "2e3f7ba1-0ec2-4b23-b29f-37667da68ce2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n"
     ]
    }
   ],
   "source": [
    "evaluatedQuery = {}\n",
    "BO = ['and', 'or', 'not']\n",
    "\n",
    "for var in (mappedQuery):\n",
    "    print(var)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
