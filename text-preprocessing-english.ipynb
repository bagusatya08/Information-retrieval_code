{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c02b10a-c9f1-44af-9a5c-9959aeff557a",
   "metadata": {},
   "source": [
    "### About Project\n",
    "This project devided into **three notebooks** that explained the usage of TF-IDF using **English.** The process flow of this project start from data collection (corpus) to pre-processing and algorithm fitting, the detailed steps explained below:\n",
    "1. **Data Collection (self-produce)**\n",
    "2. **Text Pre-Processing (Case Folding, Punctuation Removal, Tokenizing,Stop-Words Removal, Stemming)**\n",
    "3. **TF-IDF Algorithm & VSM Implementation**\n",
    "4. **Boolean Retrieval Algorithm Implementation**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e8790ff-12e6-4aef-80e0-9fc5ffeb667b",
   "metadata": {},
   "source": [
    "#### The Notebook Divided into three sub-process:\n",
    "1. text-preprocessing-english.ipynb\n",
    "2. implementation-tf-idf-and-vsm.ipynb\n",
    "3. implementation-boolean.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6915e029-9650-4a7c-95bf-df414c1bfcc8",
   "metadata": {},
   "source": [
    "## Text Preprocessing\n",
    "Text preprocessing is a crucial step in natural language processing and information retrieval. It involves transforming raw text into a more suitable format for analysis. The key steps in text preprocessing are:\n",
    "\n",
    "- **Case Folding**: This step converts all characters in the text to lowercase to ensure uniformity.\n",
    "- **Punctuation Removal**: This step eliminates punctuation marks from the text. Punctuation often does not contribute to the meaning in most text analysis tasks and can be removed to reduce noise.\n",
    "\n",
    "- **Tokenizing**: Tokenizing is the process of splitting the text into individual words or tokens. This allows for easier manipulation and analysis of the text. For example, the sentence \"Natural language processing is fun!\" would be tokenized into [\"Natural\", \"language\", \"processing\", \"is\", \"fun\"].\n",
    "\n",
    "- **Stopwords Removal**: Stopwords are common words that usually do not carry significant meaning and can be removed to focus on the more meaningful words in the text. Examples of stopwords include \"a\", \"the\", \"and\", \"in\".\n",
    "\n",
    "- **Stemming**: Stemming reduces words to their root form. For instance, \"running\", \"runner\", and \"ran\" would all be reduced to \"run\". This helps in reducing the dimensionality of the text data and focusing on the core meaning of the words.\n",
    "\n",
    "These preprocessing steps are essential for improving the quality and performance of natural language processing models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8491ea5-52d7-4234-aeca-ec784f1b5fa3",
   "metadata": {},
   "source": [
    "### Initiation of the library used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f0a4043-16b3-4fcd-9904-f236883be2eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import regex as re\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87c45b51-24de-4d40-baf4-e948d6ecf05d",
   "metadata": {},
   "source": [
    "### Importing the dataset used on this project\n",
    "p.s. for the sake of simplicity out of all the documents available, only picked out four that is the shortest and consists of only one sentence per documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb2efd8d-ec7a-4c3b-89fb-ea7819200831",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ENG1</td>\n",
       "      <td>They called him a bird, because of his habit</td>\n",
       "      <td>bird</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENG2</td>\n",
       "      <td>My brother likes bird and after a month my father gave him a black bird</td>\n",
       "      <td>bird</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ENG3</td>\n",
       "      <td>Antony has a bird and he lost it</td>\n",
       "      <td>bird</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ENG4</td>\n",
       "      <td>Greedy is the most characteristic that I hate</td>\n",
       "      <td>hate</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id                                                                     text topic\n",
       "0  ENG1                             They called him a bird, because of his habit  bird\n",
       "1  ENG2  My brother likes bird and after a month my father gave him a black bird  bird\n",
       "2  ENG3                                         Antony has a bird and he lost it  bird\n",
       "3  ENG4                            Greedy is the most characteristic that I hate  hate"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.expand_frame_repr', False)\n",
    "pd.set_option('display.max_colwidth', 1000)\n",
    "\n",
    "dataset = pd.read_csv('corpus/corpus-inggris.csv').head(4)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2cd872a-d4de-41be-8313-c696410d7d20",
   "metadata": {},
   "source": [
    "### Final Function for Text Preprocess\n",
    "This Function will be used throughtout the projects upon cleaning query. The process below (showing the breaked down steps) is the one that is used to clean the corpus before feeding it into the algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cec8c933-54c4-48cf-992d-4d01c64dc149",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "  clean_text = []\n",
    "  stemmer = PorterStemmer()\n",
    "  stop_words = set(stopwords.words('english'))\n",
    "\n",
    "  for t in text:\n",
    "      clean = re.sub(r'[^\\w\\s]', '', t.lower())\n",
    "      clean = re.sub(r'\\d+', '', clean)\n",
    "      tokens = word_tokenize(clean)\n",
    "      stemmed_tokens = [stemmer.stem(token) for token in tokens if token not in stop_words]\n",
    "      clean_text.append(' '.join(stemmed_tokens))\n",
    "\n",
    "  return clean_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "963e286b-65a8-4444-b0e7-f5766d327fe9",
   "metadata": {},
   "source": [
    "### Step-by-step Preprocessing\n",
    "#### Casefolding and Punctuation Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a682b24-2918-40e2-b623-9728da778020",
   "metadata": {},
   "outputs": [],
   "source": [
    "def casefolding_punctuationremoval(text):\n",
    "    clean_text = []\n",
    "    for t in text:\n",
    "        clean = re.sub(r'[^\\w\\s]', '', t.lower())\n",
    "        clean = re.sub(r'\\d+', '', clean)\n",
    "        clean_text.append(clean)\n",
    "    return clean_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "17d947da-756c-4033-a806-434e5c45a7e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['they called him a bird because of his habit',\n",
       " 'my brother likes bird and after a month my father gave him a black bird',\n",
       " 'antony has a bird and he lost it',\n",
       " 'greedy is the most characteristic that i hate']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_text = casefolding_punctuationremoval(dataset.text)\n",
    "clean_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd119272-07e1-4870-9e21-a3c264cabf86",
   "metadata": {},
   "source": [
    "#### Tokenizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f34d8e3-4331-44c6-a478-bdad7e57450f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizing(clean_text):\n",
    "    tokenize = []\n",
    "    for t in clean_text:\n",
    "        tokens = word_tokenize(t)\n",
    "        tokenize.append(tokens)\n",
    "    return tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c2e59319-3609-4b82-8bac-c9c42745bd80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['they', 'called', 'him', 'a', 'bird', 'because', 'of', 'his', 'habit']\n",
      "['my', 'brother', 'likes', 'bird', 'and', 'after', 'a', 'month', 'my', 'father', 'gave', 'him', 'a', 'black', 'bird']\n",
      "['antony', 'has', 'a', 'bird', 'and', 'he', 'lost', 'it']\n",
      "['greedy', 'is', 'the', 'most', 'characteristic', 'that', 'i', 'hate']\n"
     ]
    }
   ],
   "source": [
    "tokenize = tokenizing(clean_text)\n",
    "\n",
    "print('\\n'.join(map(str, tokenize)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f44eb0-d9f8-4a18-a381-7417e9a2c8a3",
   "metadata": {},
   "source": [
    "#### Stopwords Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "de1afb60-3ebe-4757-a9d9-51960d25bbfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stopwords_removal(tokenize):\n",
    "    no_stopwords = []\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    for sentence in tokenize:\n",
    "        removed_stopwords = [word for word in sentence if word not in stop_words]\n",
    "        no_stopwords.append(removed_stopwords)\n",
    "    return no_stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "64eed18a-d3fe-4f02-a5ff-66c5f34643a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['called', 'bird', 'habit']\n",
      "['brother', 'likes', 'bird', 'month', 'father', 'gave', 'black', 'bird']\n",
      "['antony', 'bird', 'lost']\n",
      "['greedy', 'characteristic', 'hate']\n"
     ]
    }
   ],
   "source": [
    "removed_stopwords = stopwords_removal(tokenize)\n",
    "print('\\n'.join(map(str, removed_stopwords)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8972853-a4ec-46e4-811d-76f602d8ec9e",
   "metadata": {},
   "source": [
    "#### Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ee9c11fa-6631-4d57-945e-aa145e99a256",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stemming(removed_stopwords):\n",
    "    stemmed = []\n",
    "    stemmer = PorterStemmer()\n",
    "    for sentence in removed_stopwords:\n",
    "        stemmed_tokens = [stemmer.stem(token) for token in sentence]\n",
    "        stemmed.append(stemmed_tokens)\n",
    "    return stemmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7dca3801-0d55-445b-9076-81ac2fc43fe2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['call', 'bird', 'habit']\n",
      "['brother', 'like', 'bird', 'month', 'father', 'gave', 'black', 'bird']\n",
      "['antoni', 'bird', 'lost']\n",
      "['greedi', 'characterist', 'hate']\n"
     ]
    }
   ],
   "source": [
    "stemmed = stemming(removed_stopwords)\n",
    "print('\\n'.join(map(str, stemmed)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f01a7e6-f92b-4570-bc4d-95db41ef5928",
   "metadata": {},
   "source": [
    "#### Joining the Result into Sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "715d42e1-1228-46b6-82f8-611903ed3116",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['call bird habit',\n",
       " 'brother like bird month father gave black bird',\n",
       " 'antoni bird lost',\n",
       " 'greedi characterist hate']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess_result = [' '.join(map(str, sentence)) for sentence in stemmed]\n",
    "preprocess_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "336a25d6-b486-4a16-a57f-32237bc93f95",
   "metadata": {},
   "source": [
    "### Transform the clean dataset dan export it into csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b81b4a2b-67d2-49f9-b06b-a9ddf1433cb1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "clean_dataset = pd.DataFrame(preprocess_result)\n",
    "clean_dataset = clean_dataset.rename(columns={0: 'teks'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "07ee4a57-737d-4ce7-a0c9-13b283b52ffd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>teks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>call bird habit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>brother like bird month father gave black bird</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>antoni bird lost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>greedi characterist hate</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             teks\n",
       "0                                 call bird habit\n",
       "1  brother like bird month father gave black bird\n",
       "2                                antoni bird lost\n",
       "3                        greedi characterist hate"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9b0903b3-9153-4e58-972a-ca3bc001fc38",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "clean_dataset.to_csv('corpus/clean-corpus-inggris.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "information",
   "language": "python",
   "name": "information"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
